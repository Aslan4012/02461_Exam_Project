{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParkingLotDataset(Dataset):\n",
    "    def __init__(self, batch_folder, labels_file):\n",
    "        \"\"\"\n",
    "        Initialize the ParkingLotDataset with lazy loading of batches.\n",
    "\n",
    "        Args:\n",
    "        - batch_folder (str): Path to the folder containing .npy batch files.\n",
    "        - labels_file (str): Path to the file containing the labels.\n",
    "        \"\"\"\n",
    "        self.batch_folder = batch_folder\n",
    "\n",
    "        # Load labels\n",
    "        with open(labels_file, 'r') as f:\n",
    "            self.labels = [int(line.split(\":\")[-1].strip()) for line in f]\n",
    "\n",
    "        # Get the list of .npy files\n",
    "        self.batch_files = sorted(os.listdir(batch_folder))\n",
    "\n",
    "        # Map labels to batches (assuming labels are in order)\n",
    "        self.num_batches = len(self.batch_files)\n",
    "        self.batch_indices = []  # Maps global index to (batch_file, batch_idx)\n",
    "        for i, batch_file in enumerate(self.batch_files):\n",
    "            batch_path = os.path.join(batch_folder, batch_file)\n",
    "            batch_data = np.load(batch_path)\n",
    "            for idx in range(len(batch_data)):\n",
    "                self.batch_indices.append((batch_file, idx))\n",
    "\n",
    "        # Check alignment of images and labels\n",
    "        assert len(self.batch_indices) == len(self.labels), (\n",
    "            \"Mismatch between the number of images and labels!\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples.\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_file, batch_idx = self.batch_indices[idx]\n",
    "        batch_path = os.path.join(self.batch_folder, batch_file)\n",
    "        batch_data = np.load(batch_path)  # Load the specific batch\n",
    "        image = batch_data[batch_idx]  # Get the specific image within the batch\n",
    "        label = self.labels[idx]  # Get the corresponding label\n",
    "        \n",
    "        # Transpose image from (H, W, C) to (C, H, W) for PyTorch\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        return torch.tensor(image, dtype=torch.float32), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: [32, 256, 256]\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "\n",
    "        # Second Convolutional Block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: [64, 128, 128]\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "\n",
    "        # Third Convolutional Block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: [128, 64, 64]\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "\n",
    "        # Fourth Convolutional Block (optional)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # Output: [256, 32, 32]\n",
    "        self.dropout4 = nn.Dropout(0.25)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(256 * 32 * 32, 128)  # Adjust input size\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Single output for regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.pool3(self.relu3(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.pool4(self.relu4(self.bn4(self.conv4(x))))  # Optional\n",
    "        x = self.dropout4(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        # print(f\"Flattened shape: {x.shape}\")  # Debugging\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/Users/aslandalhoffbehbahani/Documents/02461_Exam_Project/Processed\"\n",
    "labels_file = \"/Users/aslandalhoffbehbahani/Documents/02461_Exam_Project/Labels_Num.txt\"\n",
    "\n",
    "labels = []\n",
    "\n",
    "with open(\"/Users/aslandalhoffbehbahani/Documents/02461_Exam_Project/Labels_Num.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        # Split the line by \":\" and strip whitespace\n",
    "        label = line.split(\":\")[-1].strip()\n",
    "        # Convert the label to an integer\n",
    "        labels.append(int(label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Create dataset\n",
    "dataset = ParkingLotDataset(image_folder, labels_file)\n",
    "limited_dataset = torch.utils.data.Subset(dataset, range(1000))\n",
    "\n",
    "# Create data loader\n",
    "# train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)  # 70% for training\n",
    "val_size = int(0.15 * total_size)  # 15% for validation\n",
    "test_size = total_size - train_size - val_size  # 15% for testing\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 done\n",
      "Epoch 1/10\n",
      "Epoch [1/10], Training Loss: 2719.2394\n",
      "Epoch [1/10], Validation Loss: 1533.1974\n",
      "Epoch 2/10\n",
      "Epoch [2/10], Training Loss: 1500.3756\n",
      "Epoch [2/10], Validation Loss: 1522.7801\n",
      "Epoch 3/10\n",
      "Epoch [3/10], Training Loss: 1488.6417\n",
      "Epoch [3/10], Validation Loss: 1510.9907\n",
      "Epoch 4/10\n",
      "Epoch [4/10], Training Loss: 1477.0986\n",
      "Epoch [4/10], Validation Loss: 1498.5856\n",
      "Epoch 5/10\n",
      "Epoch [5/10], Training Loss: 1464.6872\n",
      "Epoch [5/10], Validation Loss: 1485.8445\n",
      "Epoch 6/10\n",
      "Epoch [6/10], Training Loss: 1452.1632\n",
      "Epoch [6/10], Validation Loss: 1472.9582\n",
      "Epoch 7/10\n",
      "Epoch [7/10], Training Loss: 1440.3469\n",
      "Epoch [7/10], Validation Loss: 1460.0358\n",
      "Epoch 8/10\n",
      "Epoch [8/10], Training Loss: 1426.7862\n",
      "Epoch [8/10], Validation Loss: 1447.1349\n",
      "Epoch 9/10\n",
      "Epoch [9/10], Training Loss: 1414.8759\n",
      "Epoch [9/10], Validation Loss: 1434.2589\n",
      "Epoch 10/10\n",
      "Epoch [10/10], Training Loss: 1400.9256\n",
      "Epoch [10/10], Validation Loss: 1421.4818\n",
      "Model saved!\n",
      "Test Loss: 1408.7228\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.MSELoss()  # Regression task -> Mean Squared Error loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "print(\"Step 1 done\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader, start=1):\n",
    "        images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "        print(f\"Batch {batch_idx}/{len(train_loader)}\", end=\"\\r\")\n",
    "        # print(f\"Image batch shape: {images.shape}\")  # Debugging\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.squeeze()  # Remove unnecessary dimensions\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(images).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"car_counting_cnn.pth\")\n",
    "print(\"Model saved!\")\n",
    "\n",
    "# Test phase\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
